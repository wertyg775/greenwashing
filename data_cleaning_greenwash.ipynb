{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fe910fa-a27c-4faa-803c-7a9493a1e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75586332-d862-49b3-b452-c8b6937c6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_environmental_claim(text):\n",
    "    \"\"\"\n",
    "    Detect actual environmental claims, not just keywords\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or len(str(text)) < 20:\n",
    "        return False\n",
    "    \n",
    "    text_lower = str(text).lower()\n",
    "    \n",
    "    # Stage 1: Must have environmental context words\n",
    "    environmental_phrases = [\n",
    "        # Explicit environmental claims\n",
    "        'eco-friendly', 'eco friendly', 'environmentally friendly',\n",
    "        'sustainable', 'sustainability',\n",
    "        'organic', 'certified organic',\n",
    "        'recycled', 'recyclable',\n",
    "        'biodegradable', 'compostable',\n",
    "        'carbon neutral', 'carbon footprint', 'carbon offset',\n",
    "        'zero waste', 'plastic-free', 'plastic free',\n",
    "        'fair trade',\n",
    "        'green product', 'green living',\n",
    "        'earth friendly', 'earth-friendly',\n",
    "        'planet friendly', 'planet-friendly',\n",
    "        \n",
    "        # Certifications (strong signal)\n",
    "        'gots', 'fsc certified', 'usda organic', 'grs certified',\n",
    "        'ecocert', 'oeko-tex', 'fair trade certified',\n",
    "        \n",
    "        # Materials with environmental context\n",
    "        'organic cotton', 'recycled polyester', 'recycled plastic',\n",
    "        'bamboo fiber', 'hemp fiber',\n",
    "        'post-consumer recycled', 'pre-consumer recycled'\n",
    "    ]\n",
    "    \n",
    "    # Check if any phrase exists\n",
    "    return any(phrase in text_lower for phrase in environmental_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3198547d-2b15-4e2f-b7b8-7980a8c212a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying stricter environmental claim filter...\n"
     ]
    }
   ],
   "source": [
    "# Read in chunks (for large files)\n",
    "chunk_size = 50000\n",
    "filtered_data = []\n",
    "\n",
    "print(\"Applying stricter environmental claim filter...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94b4f8ee-6e82-40a8-81ed-311cfef35028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: Found 906 environmental products\n",
      "Chunk 2: Found 890 environmental products\n",
      "Chunk 3: Found 934 environmental products\n",
      "Chunk 4: Found 914 environmental products\n",
      "Chunk 5: Found 871 environmental products\n",
      "Chunk 6: Found 912 environmental products\n",
      "Chunk 7: Found 889 environmental products\n",
      "Chunk 8: Found 925 environmental products\n",
      "Chunk 9: Found 924 environmental products\n",
      "Chunk 10: Found 869 environmental products\n",
      "Chunk 11: Found 908 environmental products\n",
      "Chunk 12: Found 864 environmental products\n",
      "Chunk 13: Found 894 environmental products\n",
      "Chunk 14: Found 926 environmental products\n",
      "Chunk 15: Found 855 environmental products\n",
      "Chunk 16: Found 949 environmental products\n",
      "Chunk 17: Found 886 environmental products\n",
      "Chunk 18: Found 935 environmental products\n",
      "Chunk 19: Found 914 environmental products\n",
      "Chunk 20: Found 902 environmental products\n",
      "Chunk 21: Found 926 environmental products\n",
      "Chunk 22: Found 979 environmental products\n",
      "Chunk 23: Found 897 environmental products\n",
      "Chunk 24: Found 903 environmental products\n",
      "Chunk 25: Found 918 environmental products\n",
      "Chunk 26: Found 915 environmental products\n",
      "Chunk 27: Found 969 environmental products\n",
      "Chunk 28: Found 884 environmental products\n",
      "Chunk 29: Found 916 environmental products\n",
      "Chunk 30: Found 923 environmental products\n",
      "Chunk 31: Found 845 environmental products\n",
      "Chunk 32: Found 913 environmental products\n",
      "Chunk 33: Found 886 environmental products\n",
      "Chunk 34: Found 929 environmental products\n",
      "Chunk 35: Found 881 environmental products\n",
      "Chunk 36: Found 875 environmental products\n",
      "Chunk 37: Found 895 environmental products\n",
      "Chunk 38: Found 916 environmental products\n",
      "Chunk 39: Found 920 environmental products\n",
      "Chunk 40: Found 823 environmental products\n",
      "Chunk 41: Found 894 environmental products\n",
      "Chunk 42: Found 900 environmental products\n",
      "Chunk 43: Found 930 environmental products\n",
      "Chunk 44: Found 885 environmental products\n",
      "Chunk 45: Found 869 environmental products\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(pd.read_csv('amazon_products.csv', chunksize=chunk_size)):\n",
    "    # Combine text fields\n",
    "    chunk['combined_text'] = (\n",
    "        chunk['TITLE'].fillna('') + ' ' +\n",
    "        chunk['DESCRIPTION'].fillna('')\n",
    "    )\n",
    "    \n",
    "    # Apply stricter filter\n",
    "    env_mask = chunk['combined_text'].apply(has_environmental_claim)\n",
    "    filtered = chunk[env_mask]\n",
    "    \n",
    "    if len(filtered) > 0:\n",
    "        filtered_data.append(filtered)\n",
    "    \n",
    "    print(f\"Chunk {i+1}: Found {len(filtered)} environmental products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ad3f38c-bccb-446c-9ae3-d3f6343d8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total after stricter filter: 40658 products\n"
     ]
    }
   ],
   "source": [
    "df_env = pd.concat(filtered_data, ignore_index=True)\n",
    "print(f\"\\nTotal after stricter filter: {len(df_env)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "240ba690-4146-4314-ba29-7cb91f19a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_false_positive(text):\n",
    "    \"\"\"\n",
    "    Detect false positives (not actual environmental claims)\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return True\n",
    "    \n",
    "    text_lower = str(text).lower()\n",
    "    \n",
    "    # False positive patterns\n",
    "    false_patterns = [\n",
    "        # Color descriptions\n",
    "        r'\\bgreen\\s+(color|shirt|dress|paint|dye)\\b',\n",
    "        r'\\bnatural\\s+(color|shade|tone)\\b',\n",
    "        \n",
    "        # Features/modes (not claims)\n",
    "        r'\\beco\\s+mode\\b',\n",
    "        r'\\bgreen\\s+screen\\b',\n",
    "        r'\\bnatural\\s+light\\b',\n",
    "        \n",
    "        # Wood/material descriptions (not claims)\n",
    "        r'\\bnatural\\s+wood\\b',\n",
    "        r'\\bnatural\\s+stone\\b',\n",
    "        \n",
    "        # Too short (likely just keywords)\n",
    "        r'^.{0,30}$'  # Less than 30 characters\n",
    "    ]\n",
    "    \n",
    "    # Check for false patterns\n",
    "    for pattern in false_patterns:\n",
    "        if re.search(pattern, text_lower):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e31f81f-2118-409e-b6fd-bbaf33ba0453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing false positives: 40089 products\n"
     ]
    }
   ],
   "source": [
    "# Remove false positives\n",
    "df_env = df_env[~df_env['combined_text'].apply(is_false_positive)]\n",
    "print(f\"After removing false positives: {len(df_env)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20f6c6c1-0dff-44b3-87d9-dd974af9eb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After length filter: 39708 products\n"
     ]
    }
   ],
   "source": [
    "# Remove very short texts (likely incomplete data)\n",
    "df_env['text_length'] = df_env['combined_text'].str.len()\n",
    "df_env = df_env[df_env['text_length'] >= 50]  # At least 50 characters\n",
    "\n",
    "print(f\"After length filter: {len(df_env)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "283ff89d-3529-4be7-8b5c-72c5a6dce434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing duplicates: 39487 products\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "df_env = df_env.drop_duplicates(subset=['combined_text'], keep='first')\n",
    "print(f\"After removing duplicates: {len(df_env)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ca69bdd-197b-4950-b3bb-78a2183f918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_claim_strength(text):\n",
    "    \"\"\"\n",
    "    Categorize how strong the environmental claim is\n",
    "    \"\"\"\n",
    "    text_lower = str(text).lower()\n",
    "    \n",
    "    # Strong claims (have certifications or metrics)\n",
    "    strong_indicators = ['certified', 'gots', 'fsc', 'usda', 'fair trade', r'\\d+%']\n",
    "    if any(re.search(ind, text_lower) for ind in strong_indicators):\n",
    "        return 'strong'\n",
    "    \n",
    "    # Medium claims (specific materials/processes)\n",
    "    medium_indicators = ['organic cotton', 'recycled polyester', 'bamboo fiber', \n",
    "                        'post-consumer', 'carbon neutral']\n",
    "    if any(ind in text_lower for ind in medium_indicators):\n",
    "        return 'medium'\n",
    "    \n",
    "    # Weak claims (just buzzwords)\n",
    "    return 'weak'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49378abe-6edc-41db-9a8f-5dc76e6c5f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claim strength distribution:\n",
      "claim_strength\n",
      "weak      24941\n",
      "strong    13569\n",
      "medium      977\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Categorize all claims\n",
    "df_env['claim_strength'] = df_env['combined_text'].apply(categorize_claim_strength)\n",
    "\n",
    "print(\"\\nClaim strength distribution:\")\n",
    "print(df_env['claim_strength'].value_counts())\n",
    "\n",
    "# Stratified sampling: Get balanced mix\n",
    "sample_sizes = {\n",
    "    'strong': 1500,   # More strong claims (easier to label as SPECIFIC)\n",
    "    'medium': 1500,   # Medium claims (mixed)\n",
    "    'weak': 1000      # Some weak claims (likely VAGUE)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa23f7c3-8e9b-450b-b7f3-738e30418695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strong: 2000\n",
      "medium: 977\n",
      "weak: 1000\n",
      "\n",
      "Total: 3977\n"
     ]
    }
   ],
   "source": [
    "# More strong/medium, fewer weak\n",
    "sample_config = {\n",
    "    'strong': 2000,   # Plenty available (13,569)\n",
    "    'medium': 977,    # Take all (only 977 available)\n",
    "    'weak': 1000      # Reduced from 24,941\n",
    "}\n",
    "\n",
    "samples = []\n",
    "for strength, target_n in sample_config.items():\n",
    "    subset = df_env[df_env['claim_strength'] == strength]\n",
    "    n = min(len(subset), target_n)\n",
    "    sample = subset.sample(n=n, random_state=42)\n",
    "    samples.append(sample)\n",
    "    print(f\"{strength}: {n}\")\n",
    "\n",
    "df_sample = pd.concat(samples, ignore_index=True)\n",
    "print(f\"\\nTotal: {len(df_sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5d910af-142d-4fbb-9f77-d421e89a729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_text(text):\n",
    "    \"\"\"\n",
    "    Remove HTML tags and clean text\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove HTML tags using BeautifulSoup\n",
    "    soup = BeautifulSoup(str(text), 'html.parser')\n",
    "    text_clean = soup.get_text()\n",
    "    \n",
    "    # Clean up extra whitespace\n",
    "    text_clean = re.sub(r'\\s+', ' ', text_clean)\n",
    "    text_clean = text_clean.strip()\n",
    "    \n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c593a16a-b92e-4dd4-b795-f56f1b263d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sampled: 3,977\n",
      "\n",
      "New distribution:\n",
      "claim_strength\n",
      "strong    2000\n",
      "weak      1000\n",
      "medium     977\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal sampled: {len(df_sample):,}\")\n",
    "print(\"\\nNew distribution:\")\n",
    "print(df_sample['claim_strength'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d6f5bd4-83d3-41d1-8873-5df2c6abf834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>claim_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1064258</td>\n",
       "      <td>L'ovedbaby Unisex-Baby Organic Cotton Footed O...</td>\n",
       "      <td>[Infant footie with snap buttons from neck to ...</td>\n",
       "      <td>OR444s-0/3M Size: 0 - 3 Months, Color: Sage Fe...</td>\n",
       "      <td>2364</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>L'ovedbaby Unisex-Baby Organic Cotton Footed O...</td>\n",
       "      <td>464</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171982</td>\n",
       "      <td>K3 Deluxe Virgin Plastic Bucket (Balti) 25 (23...</td>\n",
       "      <td>[K3 Deluxe Virgin Plastic Bucket (Balti) 25 li...</td>\n",
       "      <td>&lt;b&gt;Sturdy and Light Weight Made from 100% virg...</td>\n",
       "      <td>424</td>\n",
       "      <td>1614.173227</td>\n",
       "      <td>K3 Deluxe Virgin Plastic Bucket (Balti) 25 (23...</td>\n",
       "      <td>1370</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400935</td>\n",
       "      <td>40-Piece Flatware Set For 8, EIUBUIE 18/10 Sta...</td>\n",
       "      <td>[üëç„ÄêFINEST STAINLESS STEEL„Äë18/10 stainless-stee...</td>\n",
       "      <td>&lt;b&gt;EIUBUIE 40 Piece High Quality 18/10 Stainle...</td>\n",
       "      <td>8184</td>\n",
       "      <td>1043.000000</td>\n",
       "      <td>40-Piece Flatware Set For 8, EIUBUIE 18/10 Sta...</td>\n",
       "      <td>2160</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2924934</td>\n",
       "      <td>TUFFPAULIN 15FT X 15FT 120 GSM Silver Tarpauli...</td>\n",
       "      <td>[Actual size will be approx. half foot shorter...</td>\n",
       "      <td>TUFFPAULIN tarpaulin are made from superior qu...</td>\n",
       "      <td>10249</td>\n",
       "      <td>18000.000000</td>\n",
       "      <td>TUFFPAULIN 15FT X 15FT 120 GSM Silver Tarpauli...</td>\n",
       "      <td>1801</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2518472</td>\n",
       "      <td>Shrayati Areca Leaf Round Bowls, 5 Inch, Pack ...</td>\n",
       "      <td>[Biodegradability - Every small step towards t...</td>\n",
       "      <td>Shrayati Areca Leaf Round bowls are made from ...</td>\n",
       "      <td>1426</td>\n",
       "      <td>492.125984</td>\n",
       "      <td>Shrayati Areca Leaf Round Bowls, 5 Inch, Pack ...</td>\n",
       "      <td>627</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID                                              TITLE  \\\n",
       "0     1064258  L'ovedbaby Unisex-Baby Organic Cotton Footed O...   \n",
       "1     2171982  K3 Deluxe Virgin Plastic Bucket (Balti) 25 (23...   \n",
       "2     2400935  40-Piece Flatware Set For 8, EIUBUIE 18/10 Sta...   \n",
       "3     2924934  TUFFPAULIN 15FT X 15FT 120 GSM Silver Tarpauli...   \n",
       "4     2518472  Shrayati Areca Leaf Round Bowls, 5 Inch, Pack ...   \n",
       "\n",
       "                                       BULLET_POINTS  \\\n",
       "0  [Infant footie with snap buttons from neck to ...   \n",
       "1  [K3 Deluxe Virgin Plastic Bucket (Balti) 25 li...   \n",
       "2  [üëç„ÄêFINEST STAINLESS STEEL„Äë18/10 stainless-stee...   \n",
       "3  [Actual size will be approx. half foot shorter...   \n",
       "4  [Biodegradability - Every small step towards t...   \n",
       "\n",
       "                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
       "0  OR444s-0/3M Size: 0 - 3 Months, Color: Sage Fe...             2364   \n",
       "1  <b>Sturdy and Light Weight Made from 100% virg...              424   \n",
       "2  <b>EIUBUIE 40 Piece High Quality 18/10 Stainle...             8184   \n",
       "3  TUFFPAULIN tarpaulin are made from superior qu...            10249   \n",
       "4  Shrayati Areca Leaf Round bowls are made from ...             1426   \n",
       "\n",
       "   PRODUCT_LENGTH                                      combined_text  \\\n",
       "0      100.000000  L'ovedbaby Unisex-Baby Organic Cotton Footed O...   \n",
       "1     1614.173227  K3 Deluxe Virgin Plastic Bucket (Balti) 25 (23...   \n",
       "2     1043.000000  40-Piece Flatware Set For 8, EIUBUIE 18/10 Sta...   \n",
       "3    18000.000000  TUFFPAULIN 15FT X 15FT 120 GSM Silver Tarpauli...   \n",
       "4      492.125984  Shrayati Areca Leaf Round Bowls, 5 Inch, Pack ...   \n",
       "\n",
       "   text_length claim_strength  \n",
       "0          464         strong  \n",
       "1         1370         strong  \n",
       "2         2160         strong  \n",
       "3         1801         strong  \n",
       "4          627         strong  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.columns.tolist()\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff4af8cc-c495-4d9b-b224-f79837752fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "df_sample['combined_text'] = df_sample['combined_text'].apply(clean_html_text)\n",
    "df_sample['combined_text'] = df_sample['combined_text'].str.replace(r'\\s+', ' ', regex=True)\n",
    "df_sample['combined_text'] = df_sample['combined_text'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99ff4018-f143-4758-822b-f94459a7adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_SIZE = 100\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "df_eval_products = (\n",
    "    df_sample\n",
    "    .drop_duplicates(subset='PRODUCT_ID')\n",
    "    .sample(n=EVAL_SIZE, random_state=RANDOM_SEED)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "183a7d89-9efd-4d55-9bde-4b8ddfd64a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample[\n",
    "    ~df_sample['PRODUCT_ID'].isin(df_eval_products['PRODUCT_ID'])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c77c7ceb-acea-4bf3-96b7-8e6152035080",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(df_sample['PRODUCT_ID']).isdisjoint(\n",
    "       set(df_eval_products['PRODUCT_ID'])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58c984bc-cc12-45a6-9935-996b5cb76ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3877\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(df_sample))\n",
    "print(len(df_eval_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0cf1d569-44d7-4f27-8555-8ad06e622937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_products[['PRODUCT_ID', 'combined_text', 'claim_strength']].to_csv(\"data/eval_products_100.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3abfbaaf-913b-470a-b3c7-1230c5eff8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentence-level samples: 37,207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>claim_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22225</th>\n",
       "      <td>Due to manual measurement, please kindly allow 1.</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19034</th>\n",
       "      <td>Window panels set of 2.</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>We use flannel cotton that‚Äôs lightweight yet a...</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12032</th>\n",
       "      <td>&gt; Heavy Duty: Our Commercial Grade Balls weigh...</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11898</th>\n",
       "      <td>Drop us a line, we'll be happy to assist .</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence claim_strength\n",
       "22225  Due to manual measurement, please kindly allow 1.         strong\n",
       "19034                            Window panels set of 2.         strong\n",
       "5553   We use flannel cotton that‚Äôs lightweight yet a...         strong\n",
       "12032  > Heavy Duty: Our Commercial Grade Balls weigh...         strong\n",
       "11898         Drop us a line, we'll be happy to assist .         strong"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "\n",
    "    # Normalize bullet points and line breaks\n",
    "    text = re.sub(r'[\\r\\n‚Ä¢\\-]+', '. ', str(text))\n",
    "\n",
    "    # Split on sentence boundaries\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "    # Merge and filter short sentences\n",
    "    return [s.strip() for s in sentences if len(s.strip()) >= 20]\n",
    "\n",
    "# Create sentence-level rows\n",
    "rows = []\n",
    "\n",
    "for _, row in df_sample.iterrows():  # iterate over products\n",
    "    sentences = split_into_sentences(row['combined_text'])\n",
    "    for sent in sentences:\n",
    "        rows.append({\n",
    "            'sentence': sent,\n",
    "            'claim_strength': row['claim_strength']\n",
    "        })\n",
    "\n",
    "# Make dataframe\n",
    "df_sentences = pd.DataFrame(rows)\n",
    "\n",
    "print(f\"Total sentence-level samples: {len(df_sentences):,}\")\n",
    "df_sentences.sample(5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac398bda-93ed-41ac-97e5-41ea84b47519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "AUTO-LABELING\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# AUTO-LABEL\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"AUTO-LABELING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def auto_label(text, strength):\n",
    "    \"\"\"\n",
    "    Auto-label with claim strength as hint\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or len(str(text)) < 20:\n",
    "        return 'SKIP'\n",
    "    \n",
    "    text_lower = str(text).lower()\n",
    "    \n",
    "    # SPECIFIC indicators\n",
    "    certifications = [\n",
    "        'certified', 'certification',\n",
    "        'gots', 'fsc', 'usda organic', 'grs', \n",
    "        'fair trade', 'fairtrade',\n",
    "        'ecocert', 'oeko-tex',\n",
    "        'rainforest alliance',\n",
    "        'certified by', 'approved by', 'verified by'\n",
    "    ]\n",
    "    has_cert = any(cert in text_lower for cert in certifications)\n",
    "    \n",
    "    # Has percentages or measurements\n",
    "    has_metrics = bool(re.search(r'\\d+\\s*%|\\d+\\s*grams?|\\d+\\s*kg', text))\n",
    "    \n",
    "    # Specific materials/processes with details\n",
    "    specific_details = [\n",
    "        'organic cotton', 'recycled polyester', 'recycled plastic',\n",
    "        'post-consumer recycled', 'pre-consumer recycled',\n",
    "        'carbon neutral', 'carbon offset', 'carbon footprint'\n",
    "    ]\n",
    "    has_specific = any(detail in text_lower for detail in specific_details)\n",
    "    \n",
    "    # VAGUE indicators (just buzzwords)\n",
    "    vague_only = [\n",
    "        'eco-friendly', 'eco friendly',\n",
    "        'environmentally friendly',\n",
    "        'sustainable', 'sustainability',\n",
    "        'green', 'green product',\n",
    "        'natural', 'nature',\n",
    "        'earth friendly', 'planet friendly'\n",
    "    ]\n",
    "    has_vague_only = any(term in text_lower for term in vague_only)\n",
    "    \n",
    "    # DECISION LOGIC with strength hints\n",
    "    \n",
    "    # Strong claims: likely SPECIFIC\n",
    "    if strength == 'strong':\n",
    "        if has_cert or has_metrics:\n",
    "            return 'SPECIFIC'\n",
    "        elif has_specific:\n",
    "            return 'SPECIFIC'\n",
    "        else:\n",
    "            return 'UNCERTAIN'\n",
    "    \n",
    "    # Weak claims: likely VAGUE\n",
    "    elif strength == 'weak':\n",
    "        if has_cert or has_metrics:\n",
    "            return 'SPECIFIC'  # Even weak claims can have certs\n",
    "        elif has_vague_only and not has_specific:\n",
    "            return 'VAGUE'\n",
    "        else:\n",
    "            return 'UNCERTAIN'\n",
    "    \n",
    "    # Medium claims: mixed\n",
    "    else:  # medium\n",
    "        if has_cert or has_metrics:\n",
    "            return 'SPECIFIC'\n",
    "        elif has_specific:\n",
    "            return 'SPECIFIC'\n",
    "        elif has_vague_only:\n",
    "            return 'VAGUE'\n",
    "        else:\n",
    "            return 'UNCERTAIN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07305162-5174-4770-8c97-9ae78ce54ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence-level label distribution:\n",
      "label\n",
      "UNCERTAIN    32460\n",
      "SPECIFIC      3755\n",
      "VAGUE          992\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply labeling\n",
    "df_sentences['label'] = df_sentences.apply(\n",
    "    lambda row: auto_label(row['sentence'], row['claim_strength']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"\\nSentence-level label distribution:\")\n",
    "print(df_sentences['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9319732-8824-4bd3-b826-ce69675bad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confident sentence-level labels: 4,747\n",
      "label\n",
      "SPECIFIC    3755\n",
      "VAGUE        992\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_labeled = df_sentences[df_sentences['label'].isin(['SPECIFIC', 'VAGUE'])].copy()\n",
    "\n",
    "print(f\"\\nConfident sentence-level labels: {len(df_labeled):,}\")\n",
    "print(df_labeled['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bf12128-f30f-4bab-a46d-8015f5ddedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'SPECIFIC': 1,   # VERIFIABLE\n",
    "    'VAGUE': 0       # NON-VERIFIABLE\n",
    "}\n",
    "\n",
    "df_labeled['label_id'] = df_labeled['label'].map(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81e40e75-d7d5-4dd4-aff9-830230c762c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label breakdown by claim strength:\n",
      "label           SPECIFIC  VAGUE\n",
      "claim_strength                 \n",
      "medium               942    278\n",
      "strong              2783      0\n",
      "weak                  30    714\n"
     ]
    }
   ],
   "source": [
    "#Show label breakdown by strength\n",
    "print(\"\\nLabel breakdown by claim strength:\")\n",
    "print(pd.crosstab(df_labeled['claim_strength'], df_labeled['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be59e977-1746-4436-b145-0690c3dfbff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved 4,747 sentence-level training examples\n"
     ]
    }
   ],
   "source": [
    "df_labeled[['sentence', 'label_id']].to_csv(\n",
    "    'data/training_sentences.csv',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"‚úì Saved {len(df_labeled):,} sentence-level training examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e65480-e34f-4ce1-888c-7b6634f9557d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c006d0-4818-4b1f-ab4f-5dfc6f9df675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
